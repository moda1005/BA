{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import shap\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/raw/automotive_data_train_140.csv', sep=';')\n",
    "df['Ausfall'] = df['Ausfall'].map({'ja': 1, 'nein': 0})\n",
    "df = df.drop(['Messungsnr', 'KatTemp'], axis=1, errors='ignore')\n",
    "\n",
    "X = df.drop('Ausfall', axis=1)\n",
    "y = df['Ausfall']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train), columns=X.columns, index=X_train.index\n",
    ")\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test), columns=X.columns, index=X_test.index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAB 1: Feature Selection\n",
    "feature_selector = widgets.SelectMultiple(\n",
    "    options=list(X.columns), \n",
    "    value=list(X.columns),\n",
    "    description='Features:',\n",
    "    layout=widgets.Layout(width='400px', height='250px')\n",
    ")\n",
    "\n",
    "def show_dataset(selected_features):\n",
    "    print(f\"Selected: {len(selected_features)} features\\n\")\n",
    "    display(df[['Ausfall'] + list(selected_features)].head())\n",
    "\n",
    "data_output = widgets.interactive_output(show_dataset, {'selected_features': feature_selector})\n",
    "\n",
    "tab1 = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Select Features</h3>\"), \n",
    "    feature_selector, \n",
    "    data_output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAB 2: Tree Parameters\n",
    "min_split = widgets.IntSlider(\n",
    "    value=15, min=2, max=50, \n",
    "    description='min_split:', \n",
    "    style={'description_width': '120px'}\n",
    ")\n",
    "min_leaf = widgets.IntSlider(\n",
    "    value=3, min=1, max=20, \n",
    "    description='min_leaf:', \n",
    "    style={'description_width': '120px'}\n",
    ")\n",
    "max_depth = widgets.IntSlider(\n",
    "    value=4, min=2, max=10, \n",
    "    description='max_depth:', \n",
    "    style={'description_width': '120px'}\n",
    ")\n",
    "\n",
    "def show_tree(selected_features, min_samples_split, min_samples_leaf, max_depth_val):\n",
    "    if len(selected_features) < 2:\n",
    "        print(\"Please select at least 2 features\")\n",
    "        return\n",
    "    \n",
    "    X_tr = X_train_scaled[list(selected_features)]\n",
    "    X_te = X_test_scaled[list(selected_features)]\n",
    "    \n",
    "    model = DecisionTreeClassifier(\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_depth=max_depth_val,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_tr, y_train)\n",
    "    pred = model.predict(X_te)\n",
    "    \n",
    "    # Display metrics\n",
    "    print(\"=== Performance Metrics ===\")\n",
    "    print(f\"Accuracy:  {accuracy_score(y_test, pred)*100:.1f}%\")\n",
    "    print(f\"Precision: {precision_score(y_test, pred, zero_division=0)*100:.1f}%\")\n",
    "    print(f\"Recall:    {recall_score(y_test, pred, zero_division=0)*100:.1f}%\")\n",
    "    print()\n",
    "    \n",
    "    # Display tree\n",
    "    plt.figure(figsize=(18, 10))\n",
    "    plot_tree(model, feature_names=list(selected_features), \n",
    "              class_names=['nein', 'ja'], filled=True, rounded=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "tree_output = widgets.interactive_output(\n",
    "    show_tree, \n",
    "    {\n",
    "        'selected_features': feature_selector,\n",
    "        'min_samples_split': min_split,\n",
    "        'min_samples_leaf': min_leaf,\n",
    "        'max_depth_val': max_depth\n",
    "    }\n",
    ")\n",
    "\n",
    "tab2 = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Tree Parameters</h3>\"),\n",
    "    min_split,\n",
    "    min_leaf,\n",
    "    max_depth,\n",
    "    tree_output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAB 3: Predictions\n",
    "predict_trigger = widgets.Button(\n",
    "    description='Predict', \n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "pred_output = widgets.Output()\n",
    "\n",
    "def make_prediction(btn):\n",
    "    with pred_output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Get current values from widgets\n",
    "        selected_features = list(feature_selector.value)\n",
    "        \n",
    "        if len(selected_features) < 1:\n",
    "            print(\"⚠️ Please select at least 1 feature in Tab 1 (Datensatz)\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            X_tr = X_train_scaled[selected_features]\n",
    "            X_te = X_test_scaled[selected_features]\n",
    "            \n",
    "            model = DecisionTreeClassifier(\n",
    "                min_samples_split=min_split.value,\n",
    "                min_samples_leaf=min_leaf.value,\n",
    "                max_depth=max_depth.value,\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(X_tr, y_train)\n",
    "            pred = model.predict(X_te)\n",
    "            \n",
    "            # Create results dataframe - FIXED LINE\n",
    "            results = pd.DataFrame({\n",
    "                'Actual': y_test.map({0: 'nein', 1: 'ja'}).values,\n",
    "                'Predicted': pd.Series(pred).map({0: 'nein', 1: 'ja'}).values,\n",
    "                'Correct': pd.Series(pred == y_test.values).map({True: '✓', False: '✗'}).values\n",
    "            })\n",
    "            \n",
    "            print(f\"Accuracy: {accuracy_score(y_test, pred)*100:.1f}%\\n\")\n",
    "            display(results)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {str(e)}\")\n",
    "\n",
    "predict_trigger.on_click(make_prediction)\n",
    "\n",
    "tab3 = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Predictions</h3>\"), \n",
    "    predict_trigger, \n",
    "    pred_output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAB 4: SHAP-Analyse (INTERACTIVE) - CORRECTED\n",
    "\n",
    "shap_summary_btn = widgets.Button(description=\"Summary Plot\", layout=widgets.Layout(width='150px'))\n",
    "shap_bar_btn     = widgets.Button(description=\"Bar Plot\",     layout=widgets.Layout(width='150px'))\n",
    "shap_waterfall_btn = widgets.Button(description=\"Waterfall Plot\", layout=widgets.Layout(width='150px'))\n",
    "\n",
    "shap_output = widgets.Output()\n",
    "\n",
    "def compute_shap():\n",
    "    \"\"\"Train model on selected features + compute shap values safely.\"\"\"\n",
    "    feats = list(feature_selector.value)\n",
    "    \n",
    "    if len(feats) < 1:\n",
    "        raise ValueError(\"Please select at least 1 feature\")\n",
    "\n",
    "    model = DecisionTreeClassifier(\n",
    "        min_samples_split=min_split.value,\n",
    "        min_samples_leaf=min_leaf.value,\n",
    "        max_depth=max_depth.value,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_scaled[feats], y_train)\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test_scaled[feats])\n",
    "\n",
    "    # Binary classification: get class 1 (positive class)\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[1]\n",
    "    elif len(shap_values.shape) == 3:\n",
    "        # Shape is (n_samples, n_features, n_classes)\n",
    "        shap_values = shap_values[:, :, 1]\n",
    "\n",
    "    return explainer, shap_values, feats\n",
    "\n",
    "\n",
    "def show_shap_summary(btn):\n",
    "    with shap_output:\n",
    "        clear_output(wait=True)\n",
    "        try:\n",
    "            _, shap_values, feats = compute_shap()\n",
    "            shap.summary_plot(shap_values, X_test_scaled[feats], feature_names=feats)\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "\n",
    "def show_shap_bar(btn):\n",
    "    with shap_output:\n",
    "        clear_output(wait=True)\n",
    "        try:\n",
    "            _, shap_values, feats = compute_shap()\n",
    "            \n",
    "            # Calculate mean absolute SHAP values for each feature\n",
    "            # shap_values should now be (n_samples, n_features)\n",
    "            mean_abs_shap = np.mean(np.abs(shap_values), axis=0)\n",
    "            \n",
    "            # Sort features by importance\n",
    "            sorted_idx = np.argsort(mean_abs_shap)\n",
    "            sorted_features = [feats[i] for i in sorted_idx]\n",
    "            sorted_importance = mean_abs_shap[sorted_idx]\n",
    "            \n",
    "            # Create horizontal bar plot\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            y_pos = np.arange(len(sorted_features))\n",
    "            ax.barh(y_pos, sorted_importance, color='steelblue')\n",
    "            ax.set_yticks(y_pos)\n",
    "            ax.set_yticklabels(sorted_features)\n",
    "            ax.set_xlabel('Mean |SHAP value| (average impact on model output)', fontsize=11)\n",
    "            ax.set_title('Feature Importance', fontsize=13, fontweight='bold')\n",
    "            ax.grid(axis='x', alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            print(traceback.format_exc())\n",
    "\n",
    "\n",
    "def show_shap_waterfall(btn):\n",
    "    with shap_output:\n",
    "        clear_output(wait=True)\n",
    "        try:\n",
    "            explainer, shap_values, feats = compute_shap()\n",
    "\n",
    "            sample_idx = 0\n",
    "\n",
    "            shap_vec = shap_values[sample_idx]          # shape (n_features,)\n",
    "            sample_data = X_test_scaled[feats].iloc[sample_idx].values\n",
    "\n",
    "            # expected value (scalar)\n",
    "            base_val = explainer.expected_value\n",
    "            if isinstance(base_val, (list, np.ndarray)):\n",
    "                base_val = float(base_val[1])\n",
    "\n",
    "            # Build Explanation for one sample\n",
    "            expl = shap.Explanation(\n",
    "                values=shap_vec,\n",
    "                base_values=base_val,\n",
    "                data=sample_data,\n",
    "                feature_names=feats\n",
    "            )\n",
    "\n",
    "            shap.plots.waterfall(expl, max_display=15)\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "\n",
    "# Bind buttons\n",
    "shap_summary_btn.on_click(show_shap_summary)\n",
    "shap_bar_btn.on_click(show_shap_bar)\n",
    "shap_waterfall_btn.on_click(show_shap_waterfall)\n",
    "\n",
    "tab4 = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>SHAP-Analyse (Interaktiv)</h3>\"),\n",
    "    widgets.HBox([shap_summary_btn, shap_bar_btn, shap_waterfall_btn]),\n",
    "    shap_output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c176e172842466b81383aa0271fee78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h2>Interactive Dashboard</h2>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b947427d9f14210aebf40a510fba025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HTML(value='<h3>Select Features</h3>'), SelectMultiple(description='Features:', i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display Dashboard\n",
    "tabs = widgets.Tab(children=[tab1, tab2, tab3, tab4])\n",
    "tabs.set_title(0, 'Datensatz')\n",
    "tabs.set_title(1, 'Entscheidungsbaum')\n",
    "tabs.set_title(2, 'Vorhersage')\n",
    "tabs.set_title(3, 'SHAP-Analyse')\n",
    "\n",
    "display(widgets.HTML(\"<h2>Interactive Dashboard</h2>\"))\n",
    "display(tabs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
